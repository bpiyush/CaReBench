{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be0b246-ab21-40af-8c05-3017c2c98b15",
   "metadata": {},
   "source": [
    "> Note: use `qwen` env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc0bcc6-0a19-4db7-ae7d-2102c4ce3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"False\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.nn.functional import cosine_similarity\n",
    "# from utils.video import read_frames_decord\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shared.utils as su\n",
    "# from notebooks.eval_care_retrieval import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f94f2-7864-4411-8131-2379056d529d",
   "metadata": {},
   "source": [
    "### `TVBench`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d683ca-5425-424e-9f1c-58a8c77cd3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2405, 2405)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/scratch/shared/beegfs/piyush/datasets/TVBench\"\n",
    "video_dir = f\"{data_dir}/video\"\n",
    "csv_path = f\"{data_dir}/all_except_ntu120vids.csv\"\n",
    "assert os.path.exists(csv_path), f\"CSV file not found: {csv_path}\"\n",
    "df = pd.read_csv(csv_path)\n",
    "result_file = f\"{su.log.repo_path}/results/tvbench_except_ntu120vids.npy\"\n",
    "assert os.path.exists(result_file)\n",
    "\n",
    "# Load results\n",
    "results = np.load(result_file, allow_pickle=True)\n",
    "len(results), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab57efe5-61ea-4535-b9cf-e108effe5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mLoading model /work/piyush/pretrained_checkpoints/Qwen3-4B-Instruct-2507........  \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1131627/1696998471.py\", line 3, in <module>\n",
      "    llm = QwenWrapper(model_name=\"/work/piyush/pretrained_checkpoints/Qwen3-4B-Instruct-2507\")\n",
      "  File \"/users/piyush/projects/CaReBench/utils/qwen3_utils.py\", line 68, in __init__\n",
      "    self.model, self.tokenizer = load_model(model_name)\n",
      "  File \"/users/piyush/projects/CaReBench/utils/qwen3_utils.py\", line 14, in load_model\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 601, in from_pretrained\n",
      "    model_class = _get_model_class(config, cls._model_mapping)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 394, in _get_model_class\n",
      "    supported_models = model_mapping[type(config)]\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 807, in __getitem__\n",
      "    return self._load_attr_from_module(model_type, model_name)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 821, in _load_attr_from_module\n",
      "    return getattribute_from_module(self._modules[module_name], attr)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py\", line 733, in getattribute_from_module\n",
      "    if hasattr(module, attr):\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 2302, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/utils/import_utils.py\", line 2330, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 33, in <module>\n",
      "    from ...modeling_layers import (\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/modeling_layers.py\", line 28, in <module>\n",
      "    from .processing_utils import Unpack\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/processing_utils.py\", line 37, in <module>\n",
      "    from .image_utils import ChannelDimension, is_vision_available\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/transformers/image_utils.py\", line 60, in <module>\n",
      "    from torchvision.transforms import InterpolationMode\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n",
      "    from ._register_onnx_ops import _register_custom_op\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torchvision/ops/_register_onnx_ops.py\", line 5, in <module>\n",
      "    from torch.onnx import symbolic_opset11 as opset11\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torch/onnx/__init__.py\", line 62, in <module>\n",
      "    from ._internal.onnxruntime import (\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/torch/onnx/_internal/onnxruntime.py\", line 37, in <module>\n",
      "    import onnxruntime  # type: ignore[import]\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/onnxruntime/__init__.py\", line 23, in <module>\n",
      "    from onnxruntime.capi._pybind_state import ExecutionMode  # noqa: F401\n",
      "  File \"/users/piyush/miniconda3/envs/qwen/lib/python3.11/site-packages/onnxruntime/capi/_pybind_state.py\", line 33, in <module>\n",
      "    from .onnxruntime_pybind11_state import *  # noqa\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function __import__> returned a result with an exception set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function __import__> returned a result with an exception set"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69465ce9f12e4a7ca0fa18c11b6461ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: Number of total parameters in Qwen3ForCausalLM: 4022.468M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thinking_content': '', 'content': '42 + 3 = 45.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.qwen3_utils import QwenWrapper\n",
    "\n",
    "llm = QwenWrapper(model_name=\"/work/piyush/pretrained_checkpoints/Qwen3-4B-Instruct-2507\")\n",
    "llm.generate_answer('what is 42+3?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251f9a0-5662-4029-8459-fb3b661b2473",
   "metadata": {},
   "source": [
    "**Test on a sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7077d339-0543-4433-8c2a-588d972370fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_file': 'action_count/video_7639.mp4',\n",
       " 'video': 'video_7639.mp4',\n",
       " 'video_path': '/scratch/shared/beegfs/piyush/datasets/TVBench/video/action_count/video_7639.mp4',\n",
       " 'n_frames': 16,\n",
       " 'question': 'How many containers did the person try to cover?',\n",
       " 'options': ['2', '3', '5', '4'],\n",
       " 'generated_answer': 'container',\n",
       " 'indexed_options': ['0: 2', '1: 3', '2: 5', '3: 4'],\n",
       " 'true_answer': '5'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = np.random.randint(len(results))\n",
    "results[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc268ed9-3acf-49c2-a165-a491dd3191a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are provided an answer generated by a model and the ground truth answer.\n",
      "Your task is to judge how well the generated answer matches the ground truth.\n",
      "Rate it on a scale of 0-10 where 0 is worst and 10 is best match.\n",
      "\n",
      "Model prediction: container\n",
      "Ground truth: 5\n",
      "\n",
      "Only provide the rating number and no explanation.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thinking_content': '', 'content': '0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_true = results[j]['true_answer']\n",
    "answer_genr = results[j]['generated_answer']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are provided an answer generated by a model and the ground truth answer.\n",
    "Your task is to judge how well the generated answer matches the ground truth.\n",
    "Rate it on a scale of 0-10 where 0 is worst and 10 is best match.\n",
    "\n",
    "Model prediction: {answer_genr}\n",
    "Ground truth: {answer_true}\n",
    "\n",
    "Only provide the rating number and no explanation.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "llm.generate_answer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2193fd42-c892-44fc-85b0-b29b32e910f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67437a3fd6e94bf08a4a8a5f3789b6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating answers:   0%|          | 0/2405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = su.log.tqdm_iterator(range(len(results)), desc='Evaluating answers')\n",
    "judgements = []\n",
    "for i in iterator:\n",
    "    answer_true = results[i]['true_answer']\n",
    "    answer_genr = results[i]['generated_answer']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are provided an answer generated by a model and the ground truth answer.\n",
    "    Your task is to judge how well the generated answer matches the ground truth.\n",
    "    Rate it on a scale of 0-10 where 0 is worst and 10 is best match.\n",
    "    \n",
    "    Model prediction: {answer_genr}\n",
    "    Ground truth: {answer_true}\n",
    "    \n",
    "    Only provide the rating number and no explanation.\n",
    "    \"\"\"\n",
    "    judgement = llm.generate_answer(prompt)['content']\n",
    "    judgements.append(judgement)\n",
    "len(judgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c413f5e-7cf0-44f3-834c-c1968ce4f71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.9567567567567568)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgements = np.array(judgements).astype(int)\n",
    "judgements.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "538b1fd9-ad64-4dbd-8762-582ef8d41521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.21621621621621623)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(judgements > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2dd4883f-18d8-4bf4-a08c-4f81ee035f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with judgement 6:  31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'video_file': 'egocentric_sequence/3.4/linxiaoyu.MP4',\n",
       " 'video': '3.4/linxiaoyu.MP4',\n",
       " 'video_path': '/scratch/shared/beegfs/piyush/datasets/TVBench/video/egocentric_sequence/3.4/linxiaoyu.MP4',\n",
       " 'n_frames': 16,\n",
       " 'question': 'What is the sequence of actions shown in the video?',\n",
       " 'options': ['take up the dropper bottle, uncover the dropper bottle, squeeze the dropper, cover the dropper bottle with the dropper, put down the dropper bottle, take up the test tube, put down the test tube',\n",
       "  'put down the test tube, squeeze the dropper, cover the dropper bottle with the dropper, uncover the dropper bottle, put down the dropper bottle, take up the dropper bottle, take up the test tube',\n",
       "  'put down the test tube, squeeze the dropper, cover the dropper bottle with the dropper, uncover the dropper bottle, put down the dropper bottle, take up the test tube, take up the dropper bottle',\n",
       "  'put down the test tube, uncover the dropper bottle, cover the dropper bottle with the dropper, squeeze the dropper, put down the dropper bottle, take up the test tube, take up the dropper bottle'],\n",
       " 'generated_answer': 'pick up the dropper bottle, put down the dropper bottle, squeeze the dropper, put down the dropper bottle, pick up the test tube, put down the test tube',\n",
       " 'indexed_options': ['0: take up the dropper bottle, uncover the dropper bottle, squeeze the dropper, cover the dropper bottle with the dropper, put down the dropper bottle, take up the test tube, put down the test tube',\n",
       "  '1: put down the test tube, squeeze the dropper, cover the dropper bottle with the dropper, uncover the dropper bottle, put down the dropper bottle, take up the dropper bottle, take up the test tube',\n",
       "  '2: put down the test tube, squeeze the dropper, cover the dropper bottle with the dropper, uncover the dropper bottle, put down the dropper bottle, take up the test tube, take up the dropper bottle',\n",
       "  '3: put down the test tube, uncover the dropper bottle, cover the dropper bottle with the dropper, squeeze the dropper, put down the dropper bottle, take up the test tube, take up the dropper bottle'],\n",
       " 'true_answer': 'take up the dropper bottle, uncover the dropper bottle, squeeze the dropper, cover the dropper bottle with the dropper, put down the dropper bottle, take up the test tube, put down the test tube'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement = 6\n",
    "indices = np.where(judgements == judgement)[0]\n",
    "print(f\"Number of samples with judgement {judgement}: \", len(indices))\n",
    "j = np.random.choice(indices)\n",
    "results[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b1852ec-0c97-431f-a291-02feaf23826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.20623700623700625)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = []\n",
    "for r in results:\n",
    "    a = r['true_answer'].strip().lower()\n",
    "    b = r['generated_answer'].strip().lower()\n",
    "    correct.append(a in b or b in a)\n",
    "np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2f01a-298d-492b-b6f4-39b0b6b9085a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ea045d9-cd29-41ec-a9b1-2aa6c02bd420",
   "metadata": {},
   "source": [
    "### NextQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c846fca-b170-48aa-aa93-69f18a311e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file: /scratch/shared/beegfs/piyush/datasets/NExTQA/mc.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7854, 8564)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load NextQA dataset\n",
    "data_dir = \"/scratch/shared/beegfs/piyush/datasets/NExTQA\"\n",
    "csv_path = f\"{data_dir}/mc.csv\"\n",
    "print(f\"CSV file: {csv_path}\")\n",
    "video_dir = f\"{data_dir}/NExTVideo\"\n",
    "assert os.path.exists(csv_path), f\"CSV file not found: {csv_path}\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "name = \"tarsier7b-nextqa_mc.npy\"\n",
    "# name = \"nextqa_mc.npy\"\n",
    "result_file = f\"{su.log.repo_path}/results/{name}\"\n",
    "\n",
    "# Load results\n",
    "results = np.load(result_file, allow_pickle=True)\n",
    "len(results), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8929b683-714d-4fb2-b0ff-403a1bba4fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video': np.int64(3626207014),\n",
       " 'video_path': '/scratch/shared/beegfs/piyush/datasets/NExTQA/NExTVideo/3626207014.mp4',\n",
       " 'n_frames': 16,\n",
       " 'question': 'why did the two children go under the man s legs?',\n",
       " 'options': ['kissing the leg',\n",
       "  'to pose for photo',\n",
       "  'pick up toys',\n",
       "  'kiss the ground',\n",
       "  'play'],\n",
       " 'generated_answer': 'Answer: 3: kiss the ground',\n",
       " 'indexed_options': ['0: kissing the leg',\n",
       "  '1: to pose for photo',\n",
       "  '2: pick up toys',\n",
       "  '3: kiss the ground',\n",
       "  '4: play'],\n",
       " 'true_answer': '4: play'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = np.random.randint(len(results))\n",
    "results[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e2e4e10-98a6-4485-a7e7-4f46aa3f7ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are provided an answer generated by a model and the ground truth answer.\n",
      "Your task is to judge how well the generated answer matches the ground truth.\n",
      "Rate it on a scale of 0-10 where 0 is worst and 10 is best match.\n",
      "\n",
      "Model prediction: Answer: 3: kiss the ground\n",
      "Ground truth: 4: play\n",
      "\n",
      "Only provide the rating number and no explanation.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thinking_content': '', 'content': '0'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_true = results[j]['true_answer']\n",
    "answer_genr = results[j]['generated_answer']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are provided an answer generated by a model and the ground truth answer.\n",
    "Your task is to judge how well the generated answer matches the ground truth.\n",
    "Rate it on a scale of 0-10 where 0 is worst and 10 is best match.\n",
    "\n",
    "Model prediction: {answer_genr}\n",
    "Ground truth: {answer_true}\n",
    "\n",
    "Only provide the rating number and no explanation.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "llm.generate_answer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71df0cb6-8beb-4a13-b32e-44659fed51a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fef73a4e0a49c991df9168ef3f5145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating answers:   0%|          | 0/7854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7854"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator = su.log.tqdm_iterator(range(len(results)), desc='Evaluating answers')\n",
    "judgements = []\n",
    "for i in iterator:\n",
    "    answer_true = results[i]['true_answer']\n",
    "    answer_genr = results[i]['generated_answer']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are provided an answer generated by a model and the ground truth answer.\n",
    "    Your task is to judge how well the generated answer matches the ground truth.\n",
    "    Rate it on a scale of 0-10 where 0 is worst and 10 is best match.\n",
    "    \n",
    "    Model prediction: '{answer_genr}'\n",
    "    Ground truth: '{answer_true}'\n",
    "    \n",
    "    Only provide the rating number and no explanation.\n",
    "    \"\"\"\n",
    "    judgement = llm.generate_answer(prompt)['content']\n",
    "    judgements.append(judgement)\n",
    "len(judgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c180368-7bf7-43bf-9f6b-2ad107ba4430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10,  0, ...,  0,  0, 10], shape=(7854,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(judgements).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e40574d9-ac34-40fa-8c3f-cf50bb816ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.767125031830914)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgements = np.array(judgements).astype(int)\n",
    "judgements.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b1254e28-9519-4674-af82-b8fea2408020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6159918512859689)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(judgements > 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1679b99e-1f9e-4442-af2d-ef71644aeaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.126e+03, 0.000e+00, 1.400e+01, 0.000e+00, 1.054e+03, 0.000e+00,\n",
       "        3.000e+01, 0.000e+00, 3.000e+00, 0.000e+00, 4.290e+02, 0.000e+00,\n",
       "        5.000e+00, 0.000e+00, 1.700e+01, 0.000e+00, 5.400e+01, 0.000e+00,\n",
       "        7.200e+01, 4.096e+03]),\n",
       " array([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n",
       "         5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(judgements, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9687d59c-c2b6-4c04-97bf-8673f21d638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video': np.int64(4242382178),\n",
       " 'video_path': '/scratch/shared/beegfs/piyush/datasets/NExTQA/NExTVideo/4242382178.mp4',\n",
       " 'n_frames': 16,\n",
       " 'question': 'why does the lady in green starts clapping near the end?',\n",
       " 'options': ['acting',\n",
       "  'present something',\n",
       "  'dance routine',\n",
       "  'following rhythm',\n",
       "  'emphasise point'],\n",
       " 'generated_answer': 'The video shows that the lady in green starts clapping near the end because she is following a rhythm set by the music.',\n",
       " 'indexed_options': ['0: acting',\n",
       "  '1: present something',\n",
       "  '2: dance routine',\n",
       "  '3: following rhythm',\n",
       "  '4: emphasise point'],\n",
       " 'true_answer': '3: following rhythm'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.where(judgements == 3)[0]\n",
    "j = np.random.choice(indices)\n",
    "results[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae013cb7-d009-44bb-8db6-c32d2020f8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6900"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = results[j]\n",
    "\n",
    "generated_answers = []\n",
    "for r in results:\n",
    "    generated_answers.append(r['generated_answer'].split(\":\")[-1].strip())\n",
    "len(generated_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a6484de9-215c-416c-ac33-c66fadbd1fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['true_answer'].split(':')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "119c8a0e-5d85-45a9-ab6b-267712dcdeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6900"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_answers = [r['true_answer'].split(':')[1].strip() for r in results]\n",
    "len(actual_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "242d133d-e959-402f-aeec-a1dd13ff811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.603768115942029)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(\n",
    "    np.array(actual_answers) == np.array(generated_answers)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0e8fc-aa10-4d38-ae89-e9e05c7b3152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2352f0d0-6225-4200-934d-589f4ba9efd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6f345-c3ce-46c9-a96c-e48e191c8a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6083e-364c-43ee-bdd6-9bd9f219beae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
